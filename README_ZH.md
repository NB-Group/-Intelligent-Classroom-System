# 学生课堂行为检测项目

文档语言|document language
[中文]|[[英文](README.md)]

#--------------------------
该项目由梁皓文(github@nb_group)开发、编写。

这是一个使用人工智能计算机视觉技术来检测学生在课堂上的行为的项目，可以帮助教师了解学生的学习情况和注意力分布。

## 创作背景
在我班的教育环境中，学生上课分心，与他人讲话等现象都愈发严重，甚至于无视台上的老师，但是在这样的复杂环境中，老师无法快速准确的定位说话的人，因此，我开发了一个基于人工智能的课堂行为检测系统。该系统旨在通过技术手段帮助老师对学生的学习行为进行分析，为教学效果分析提供更多的数据支持。
随着科技的不断进步，人工智能已经逐渐渗透到我们生活的各个领域。在计算机的帮助下，我们能够高效，准确的找出扰乱纪律的人并进行惩罚。结合家长签名，写检讨等方法后，该系统预计将大幅提高我班上课效果。


## 技术介绍

该项目使用[YOLOV8](https://github.com/ultralytics/ultralytics)进行图像分割，将课堂场景中的每个学生分割出来，并送入一个自定义的CNN卷积神经网络模型进行行为分类。该模型由梁皓文从零设计，并使用自己收集和标注的数据集进行训练，准确率高达**99.86%**,最后使用[face_recognition](https://github.com/ageitgey/face_recognition/)进行人脸识别。

行为检测模型可以识别出学生的以下行为：
- 听见
- 喝水
- 心不在焉
- 写字


## 使用教程

虽然这个项目是给我们班的老师用的，但是我还是简短写一下教程吧

使用该项目非常简单，只需以下几步：

1. 使用git克隆该项目或者直接下载源码压缩包
2. 使用:'''pip install -r requirements.txt'''
3. 注册ultralytics账号，获取部署用的api key,并填入config.py文件中
4. 运行Facial data input.py按照提示输入人脸数据
5. 运行main.py文件使用摄像头实时检测，或者运行use_vido_recegonition.py使用现有视频进行检测
6. 等待检测结果显示在屏幕上，或者保存到指定的文件夹中。

各个目录解释:
 - data:姿态检测模型训练数据
 - debug:我自己debug用的
 - face_data:人脸数据
 - img:本身不需要，我debug用，程序引用了，莫删
 - model:行为检测模型
 - test_data:测试数据

该项目无需其他配置，并且可以在CPU上运行，有硬件条件的可以尝试修改代码并使用GPU运行，速度会大幅提高.

## 开源协议

该项目使用[GPL v3.0](https://github.com/KSXGitHub/GPL-3.0/blob/89c928a17db494bb6f4c4013d77f5bee076d057d/LICENSE)
开源协议，任何人都可以自由地使用、修改和分发该项目，但必须保留原作者的版权信息和协议声明。并且！绝对！禁止！商用！但是想要在自己学校部署的话可以找我
